Predicting Outcomes for New Data
================================

This section is pretty straightforward and - as you might have guessed
- deals with predicting target values for new observations. It is
implemented the same way as most of the other predict methods in R, i.e. just 
call predict_ on the object returned by train_ and pass the data to be predicted.


Quick start
-----------

Classification example
......................

Let's train a Linear Discriminant Analysis on the iris data and make predictions 
for the same data set.

<<>>=
library("mlr")

task <- makeClassifTask(data = iris, target = "Species")
lrn <- makeLearner("classif.lda")
mod <- train(lrn, task = task)
predict(mod, newdata = iris)
@ 


Regression example
..................

We fit a simple linear regression model to the BostonHousing data set and predict
on the training data.

<<>>=
library("mlr")
library("mlbench")
data(BostonHousing)

task <- makeRegrTask(data = BostonHousing, target = "medv")
lrn <- makeLearner("regr.lm")
mod <- train(lrn, task)
predict(mod, newdata = BostonHousing)
@


Further information
-------------------

There are several possibilities how to pass the observations for which 
predictions are required.
The first possibility, via the ``newdata``-argument, was already shown in the 
examples above.
If the data for which predictions are required are already contained in 
the Learner_, it is also possible to pass the task and optionally specify 
the subset argument that contains the indices of the test observations.

Predictions are encapsulated in a special Prediction_ object. Read the
documentation of the Prediction_ class to see all available
accessors.


Classification example
......................

In case of a classification task, the result of predict_ depends on 
the predict type, which was set when generating the Learner_. Per default, 
class labels are predicted.

We start again by loading **mlr** and creating a classification task for the 
iris dataset. We select two subsets of the data. We train a decision tree on the
first one and predict_ the class labels on the test set.

<<>>=
library("mlr")

# At first we define the classification task.
task <- makeClassifTask(data = iris, target = "Species")

# Define the learning algorithm
lrn <- makeLearner("classif.rpart")

# Split the iris data into a training set for learning and a test set.
training.set <- seq(from = 1, to = nrow(iris), by = 2)
test.set <- seq(from = 2, to = nrow(iris), by = 2)

# Now, we can train a decision tree using only the observations in ``train.set``:
mod <- train(lrn, task, subset = training.set)

# Finally, to predict the outcome on new values, we use the predict method:
pred <- predict(mod, newdata = iris[test.set,])
@ 

A data frame that contains the true and predicted class labels can be accessed via

<<>>=
head(pred$data)
@

Alternatively, we can also predict directly from a task:

<<>>=
pred <- predict(mod, task = task, subset = test.set)
head(as.data.frame(pred))
@ 

When predicting from a task, the resulting data frame contains an additional column, 
called ID, which tells us for which element in the original data set the prediction 
is done. 
(In the iris example the IDs and the rownames coincide.)

In order to get predicted posterior probabilities, we have to change the ``predict.type``
of the learner.

<<>>=
lrn <- makeLearner("classif.rpart", predict.type = "prob")
mod <- train(lrn, task)
pred <- predict(mod, newdata = iris[test.set,])
head(pred$data)
@ 

As you can see, in addition to the predicted probabilities, a response
is produced by choosing the class with the maximum probability and
breaking ties at random.

The predicted posterior probabilities can be accessed via the getProbabilities_-function.

<<>>=
head(getProbabilities(pred))
@ 


Binary classification
.....................

In case of binary classification, two things are noteworthy. As you might recall, 
we can specify a positive class when generating the task. Moreover, we can set the
threshold value that is used to assign class labels based on the predicted 
posteriors.

To illustrate binary classification we use the Sonar dataset from the
mlbench_ package. Again, we create a classification task and a learner, which 
predicts probabilities, train the learner and then predict the class labels.


<<>>=
library("mlbench")
data(Sonar)

task <- makeClassifTask(data = Sonar, target = "Class", positive = "M")
lrn <- makeLearner("classif.rpart", predict.type = "prob")
mod <- train(lrn, task = task)
pred <- predict(mod, task = task)
head(pred$data)
@ 

In a binary classification setting, we can adjust the threshold, used
to map probabilities, to class labels using setThreshold_. Here, we set
the threshold for the *positive* class to 0.8:

<<>>=
pred <- setThreshold(pred, 0.8)
head(pred$data)
pred$threshold
@


Regression example
..................

We again use the BostonHousing data set and learn a Gradient Boosting
Machine. We use every second observation for training/test. The
proceeding is analog to the classification case.

<<>>=
library(mlbench)
data(BostonHousing)

task <- makeRegrTask(data = BostonHousing, target = "medv")

training.set <- seq(from = 1, to = nrow(BostonHousing), by = 2)
test.set <- seq(from = 2, to = nrow(BostonHousing), by = 2)

lrn <- makeLearner("regr.gbm", n.trees = 100)
mod <- train(lrn, task, subset = training.set) 

pred <- predict(mod, newdata = BostonHousing[test.set,])

head(pred$data)
@

.. _train: http://www.statistik.tu-dortmund.de/~bischl/rdocs/mlr/html/train.html
.. _Learner: http://www.statistik.tu-dortmund.de/~bischl/rdocs/mlr/html/makeLearner.html
.. _Prediction: http://www.statistik.tu-dortmund.de/~bischl/rdocs/mlr/html/Prediction.html
.. _predict: http://www.statistik.tu-dortmund.de/~bischl/rdocs/mlr/html/predict.WrappedModel.html
.. _getProb: http://www.statistik.tu-dortmund.de/~bischl/rdocs/mlr/html/getProbabilities.html
.. _setThreshold: http://www.statistik.tu-dortmund.de/~bischl/rdocs/mlr/html/setThreshold.html
.. _mlbench: http://cran.r-project.org/web/packages/mlbench/index.html
