<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
	<title>Resampling strategies</title>
	<link rel="stylesheet" type="text/css" href="formats.css">
	<style type="text/css">
	</style>
</head>

<body>
<h1>Resampling strategies</h1>

<p>Resampling strategies concern the process of sampling new data sets from your data set D under examination.
If you want to read a sound introduction into the theory and common approaches I recommend 
<a href="http://www.springerlink.com/content/m05075577v636814/">Resampling Strategies for Model Assessment and Selection</a>
as a possible start.
 
Usually one wants to generate various training and test sets, which the learning method can be fitted and validated on. 
Here it is assumed that every resampling strategy consists of a couple of iterations, where for each one 
there are indices into D, defining the respective training and test sets. These iterations are implemented by 
storing the index set in a so called <a href="rdocs/ResampleInstance-class.html">ResampleInstance</a> object. The reasons for having the user 
create this data explicitly and not just set an option in a R function to choose the resampling method are:</p>
</p>
<ul>
	<li> It is easier to create paired experiments, where you train and test different methods on exactly 
the same sets, especially when you want to add another method to a comparison experiment you already did.
	<li> It is easy to add other resampling methods later on. You can simply use S4 inheritance, derive 
from the <a href="rdocs/ResampleInstance-class.html">ResampleInstance</a> class, but you do not have to touch any methods that use the resampling strategy.  
</ul>

If you don't care about explicitly constructing the indexs sets, we create a description object, 
which stores all information we need for resampling with the function <a href="rdocs/makeResampleDesc.html">


<p><img src="pics/Resampling.png" width="40%"  border="1" alt=""></p>


<h2>Included strategies</h2>
<p>The packages come with quite a lot of predefined strategies. Let's look at the most common ones. 

</p>

<p><u>Subsampling</u></p>

<p>In each iteration i the data set D is randomly partitioned into a training and a test set according to a 
given percentage (maybe 2/3 training, 1/3 test set). If there is just one iteration, the strategy is commonly 
called <term>holdout</term> or <term>test sample estimation</term>.</p>
<pre>
	<com># split is the training set percentage</com>
	makeResampleDesc("subsample", iters = 10, split = 2/3)

	<com># holdout</com>
	makeResampleDesc("Holdout", split = 2/3)
</pre>



<P><u>k-fold cross-validation</u></P>
<p>The data set is partitioned in k subparts of (nearly) equal size. In the i.th step of the k iterations, 
the i.th subpart is used as a test set, while the remaining parts form the training set.</p>
<pre>
	rin <- makeResampleDesc("cv", iters = 10)
</pre>

<P><u>Bootstrapping</u></P>
<p>B new data sets D<sub>1</sub>,..,D<sub>B</sub> are drawn from D with replacement, each of the same size as D. 
In the i.th iteration D<sub>i</sub> forms the training set, while the remaining elements not occuring in the training set form the test set.</p>
<pre>
	rin <- makeResampleDesc("bs", iters = 10)
</pre>

<p><img src="pics/resampling.[desc, instance].png" width="40%"  border="1" alt=""></p>


<p><img src="pics/Nested_Resampling.png" width="60%"  border="1" alt=""></p>

<h2>Further details</h2>
<p>
For every resampling strategy there is a description class inheriting from <a href="rdocs/ResampleDesc-class.html">ResampleDesc</a> (which completely 
characterizes the necessary parameters) and a class inheriting from <a href="rdocs/resample.instance-class.html">resample.instance</a>. This latter class 
takes the description object and takes care of the random drawing of indices. While this seems overly 
complicated, it is necessary as sometimes one only wants to describe the drawing process, while in other 
instances one wants to create the concrete index sets. Also, there are convenience methods, to make the 
construction process as easy as possible. Here is an example for cross-validation:
</p>
<pre>
	<com># create a description for 10-fold cross-validation </com>
	desc <- new("cv.desc", iters = 10)
	<com># create the resample.instance, which defines the train/test indices </com>
	rin <- new("cv.instance", desc = desc, size = nrow(iris))
	<com># get the cv.instance directly </com>
	rin <- make.res.instance("cv", iters = 10, size = nrow(iris))
</pre>


<P>
Asking the desc or <a href="rdocs/resample.instance-class.html">resample.instance</a> object for further information is easy, just use [ ] as the generic 
getter operator:

<pre>
	<com># description object</com>
	<com># number of iterations</com>
	desc["iters"]
	<res>
	[1] 10
	</res>
	
	<com># resample.instance object</com>
	<com># number of iterations</com>
	rin["iters"]
	<res>
	[1] 10
	</res>
	
	<com># train/test indices for third iteration</com>
	rin["train.inds", 3]
	<res>
	[1]   1 118  45  33  31  13  40  63  75  91   7  70 106   6  67 117  14 123
	[19]  24  77  47 109  82  58  93  55 126  69  54 125  42  43  20  19  16  38
	...
	[127]  12  44  17  94 119  18 144  34  25
	</res>
	rin["test.inds", 3]
	<res>
	[1]  28  29  56  72  78  79  84  97  99 108 115 120 124 133 139
	</res>
	<com># train/test indices for first and third iteration</com>
	rin["train.inds", c(1,3)]
	rin["test.inds", c(1,3)]
	<res>
	$`1`
	 [1]   1   2   5   8   9  12  24  26  50  60  69  91 103 107 134
	
	$`3`
	 [1]  28  29  56  72  78  79  84  97  99 108 115 120 124 133 139
	</res>
</pre>
<P>
Please refer to the help pages of the specific classes for a complete list of getters.
<P>
If you want to validate your classification method, using a certain resampling strategy, simply call <a href="rdocs/resample.html">resample</a>. <br>
For the example code, we use the standard iris data set and compare with cross-validation a 
Decision Tree and the Linear Discriminant Analysis:
<pre>
	<com># Classification task</com>
	ct <- makeClassifTask(data = iris, target = "Species")

	<com># Resample instance for Cross-validation</com>
	rin <- makeResampleDesc("cv", iters = 3)
	rin <- make.res.instance(rin, task = ct)

	<com># Merge learner, i.e. Decision Tree, classification task ct and resample instance rin</com>
	f1 <- resample("classif.rpart", ct, rin)
	<com># Let's set a couple of hyperparameters for rpart</com>
	wl <- makeLearner("classif.rpart", minsplit = 10, cp = 0.03)
	f1 <- resample(wl, ct, rin, list(mmce, acc))	
	<com># Second resample for LDA as learner </com>
	f2 <- resample("classif.lda", ct, rin, list(mmce, acc))	

	<com># Let's see how well both classifiers did w.r.t mean misclassification error and accuracy</com>
	f1
	<res>

	</res>
	f2	
	<res>

	</res>
</pre>

<!--
<h2>How to implement another resampling strategy</h2>
<P>
If you would like to use another resampling process, you have two options: If you think something useful is missing 
from the package, please email me! Otherwise you can easily extend it yourself. <P>
Lets assume we want to implement the following (nonsensical) strategy, called "foo": In the i.th iteration draw "bar" 
times i elements from D with replacement for the training set, the remaining elemnents form the test set.

   
<pre>
	# first the resample description

	# we inherit from resample.desc
	setClass("foo.desc", contains="resample.desc")
	
	# constructor
	setMethod(f = "initialize",	signature = "foo.desc",
		def = function(.Object, bar, iters) {
			.Object@bar <- bar
			# call super-constructor
			callNextMethod(.Object, instance.class="foo.instance" name="stupid foo strategy", iters=iters)
		}
	)

	# now the resample instance, the actual drawing

	# we inherit from resample.instance
	setClass("foo.instance", contains="resample.instance")                                                     

	# constructor
	setMethod(f = "initialize",	signature = "subsample.instance",
		def = function(.Object, desc, size) {
			# draw the training indices
			inds <- lapply(1:desc["iters"], function(i) sample(1:size, i*desc["bar"]))
			# super methods takes care of the rest
			callNextMethod(.Object, desc=desc, size=size, inds=inds)
		}
	)
	
	# convenience construction method
	make.foo.instance <- function(size, bar, iters) {
		desc <- new("foo.desc", iters=iters, bar=bar)
		return(new("foo.instance", desc=desc, size=size))
	}
)
</pre>
-->



</body>
</html>
