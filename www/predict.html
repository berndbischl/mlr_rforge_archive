


<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN">
<html>
<head>
	<title>Predictions</title>
	<link rel="stylesheet" type="text/css" href="formats.css">
	<style type="text/css">
	</style>
</head>

<body>


<h1>Predictions</h1>

<P>This section is pretty straightforward and - as you might have guessed - deals with predicting target values 
for new observations. It is implemented the same way as most of the other predict methods in R, but
predictions are encapsulated in a apecial object. Read the documentation of class prediction to see all
available accessors.<br>

<P>Classification methods can predict class labels and probabilities if the algorithm supports it (you can check the wrapped learner description for this, 
see <a href="learner.html">Wrapped learner</a>). <br>
Normally you simply choose between the two by using the "type" parameter of the predict method, but in some
cases it might be preferable to encode this directly into the learner object. Both ways are demonstrated in the example below.</P>  

<P>Regression methods work the same way, but simply predict numerical values.</P>



<h3>Classification example</h3>

<pre>
	<com># classification task with iris data set </com>
	ct <- make.task(data = iris, target = "Species")
	
	<com># some indices for training and test set definition, every second observation</com>
	train.set <- seq(from = 1, to = 150, by = 2)
	test.set <- seq(from = 2, to = 150, by = 2)

	<com># train a decision tree on the training set </com>
	m <- train("classif.rpart", ct, subset = train.set)
 
	<com># predict classes for training data</com>
	predict(m, newdata = iris[train.set,])
	<res>
	Prediction
	'data.frame':	75 obs. of  2 variables:
	 $ response: Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...
	 $ truth   : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...	
	</res>
	<com># predict classes for new data</com>
	predict(m, newdata = iris[test.set,])
	<res>
	Prediction
	'data.frame':	75 obs. of  2 variables:
	 $ response: Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...
	 $ truth   : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...
	</res>
	<com># let's access the response or true labels</com>
	<com># produces a factor of predicted class</com>
	p["response"]
	
	<com># produces a factor of the true labels</com>
	p["truth"]

	<com># we can also predict directly from a task</com>
	<com># this is the same as using newdata=iris[test.set, ]</com>
	p <- predict(m, task = ct, subset = test.set)
	
	<com># again we can access the response or true labels</com>
	p["response"]
	p["truth"]
	
	<com># we also have IDs, because we know which elements of the task we used for predict</com>
	p["id"]
	<res>
  	[1]    2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38  40  42  44  46
	[24]  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76  78  80  82  84  86  88  90  92
	[47]  94  96  98 100 102 104 106 108 110 112 114 116 118 120 122 124 126 128 130 132 134 136 138
	[70] 140 142 144 146 148 150	
	</res>
	
	<com># let's predict some probabilities</com>
	p <- predict(m, newdata = iris[test.set,], type = "prob")
	<res>
	Prediction
	'data.frame':   75 obs. of  5 variables:
	 $ truth          : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...
	 $ prob.setosa    : num  1 1 1 1 1 1 1 1 1 1 ...
	 $ prob.versicolor: num  0 0 0 0 0 0 0 0 0 0 ...
	 $ prob.virginica : num  0 0 0 0 0 0 0 0 0 0 ...
	 $ response       : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...	
	 </res>
	<com># as you can see a reponse is also produced from the probabilities by choosing the class with 
	maximum probability - breaking ties at random</com>
	<com># accessing the probabilities </com>
	<com># produces a matrix with class labels as column names </com>
	p["prob"]
	
	<com># produces a numeric vector of probabilities for a class </com>
	p["prob", class = "setosa"]

	<com># let's neatly collect everything in a data.frame</com>
	as.data.frame(p)	
	<res>
	         truth prob.setosa prob.versicolor prob.virginica   response
	2       setosa           1            0.00           0.00     setosa
	4       setosa           1            0.00           0.00     setosa
	...
	150  virginica           0            0.04           0.96  virginica
	</res>
	
	<com># for binary classification you there are two special things to keep in mind</com>
	library(mlbench); data(Sonar)
	ct <- make.task(data = Sonar, target = "Class")
	m <- train("classif.rpart", task = ct)
	p <- predict(m, task=ct, type = "prob")
	
	<com># if we access the probabilities, not a matrix is returned but a vector of probabilities fpr the positive class</com>
	p["prob"]
	
	<com># but you still can explicitly select the class</com>
	p["prob", class = "M"]
	
	<com># also you might want to change the treshold probability for the positive class</com>
	<com># usually this is 0.5, but it can be set to any value between 0 and 1</com>
	p <- predict(m, task = ct, type = "prob", threshold = 0.7)

	<com># you can also directly encode into the learner that you want to predict probabilities</com>
	wl <- make.learner("classif.rpart", predict.type = "prob", predict.threshold = 0.7)
	m <- train(wl, task=ct)
	p <- predict(m, task=ct)
	
	<com># although the advantage is not obvious for this, this will come in handy later...</com>
</pre>


<h3>Binary Classification</h3>

<pre>
	<com># load binary problem</com>
	
	
	
</pre>


<h3>Regression example</h3>

<p> We again use the BostonHousing data set and learn a Gradient Boosting Machine. 
We use every second observation for training/test. <br>
The proceeding is analog to above. </p>

<pre>

	<com># Regression task</com>
	library(mlbench); data(BostonHousing)
	rt <- make.task(data = BostonHousing, target = "medv")

	<com># Training and test set </com>
	train.set <- seq(from = 1, to = 506, by = 2)
	test.set <- seq(from = 2, to = 506, by = 2)

	<com># Gradient Boosting Machine on training set </com>
	m <- train("regr.gbm", rt, subset = train.set, parset = list(n.trees = 100)) 

	<com># Predict test set data </com>
	pred <- predict(m, newdata = BostonHousing[test.set,])
	<res>
	Prediction
	'data.frame':   253 obs. of  2 variables:
 	 $ truth   : num  21.6 33.4 28.7 27.1 18.9 18.9 20.4 19.9 17.5 18.2 ...
 	 $ response: num  22.3 23.2 22.4 22.1 22.1 ...
 	</res>
	
	<com># access more information </com>
	<com># what was predicted?</com>
	pred["response"] 
	<res>
	[1] 22.25909 23.23955 22.35183 22.13662 22.13662 22.14698 22.32510 22.32510 22.14698 22.14698
	[11] 22.14698 22.13662 22.13662 22.13662 22.14698 22.14698 22.13662 22.23439 22.32510 22.49140
	...
	[241] 22.35335 22.14698 22.14698 22.14698 22.13662 22.13662 22.14698 22.13662 22.14698 22.14698
	[251] 22.23439 22.76807 22.33814
	</res>
	<com># what is the true value?</com>
	pred["truth"]
	<res>
	[1] 21.6 33.4 28.7 27.1 18.9 18.9 20.4 19.9 17.5 18.2 19.6 14.5 13.9 14.8 21.0 14.5 13.1 18.9 21.0
	[20] 30.8 26.6 24.7 19.3 16.6 19.4 20.5 23.4 35.4 31.6 19.6 16.0 25.0 23.5 22.0 20.9 21.7 23.4 21.4
	...
	[229] 13.5 20.0 17.7 20.2 19.9 19.1 20.1 19.6 29.8 13.3 12.0 21.4 23.7 21.8 21.2 20.6  7.0 13.6 21.8
	[248] 23.1 18.3 17.5 22.4 23.9 11.9
	</res>
	
</pre>

</body>
</html>
